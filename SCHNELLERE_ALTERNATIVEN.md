# Schnellere Alternativen zu OpenAI Whisper

## üöÄ √úbersicht der Alternativen

### 1. **faster-whisper** (Empfohlen!)
- **Geschwindigkeit:** 4-5x schneller als OpenAI Whisper
- **Qualit√§t:** Identisch zu OpenAI Whisper
- **Installation:** `pip install faster-whisper`
- **Vorteile:**
  - CTranslate2 backend f√ºr optimierte Inferenz
  - Geringerer Speicherverbrauch
  - Unterst√ºtzt alle Whisper-Modelle
  - CPU und GPU Support

### 2. **whisper.cpp**
- **Geschwindigkeit:** 3-4x schneller
- **Qualit√§t:** Sehr nah an Original
- **Installation:** 
  ```bash
  git clone https://github.com/ggerganov/whisper.cpp
  cd whisper.cpp
  make
  ```
- **Vorteile:**
  - C++ Implementierung
  - Sehr geringer Speicherverbrauch
  - L√§uft auf √§lteren Ger√§ten

### 3. **WhisperX**
- **Geschwindigkeit:** 2-3x schneller + bessere Timestamps
- **Qualit√§t:** Verbesserte Wort-Level Timestamps
- **Installation:** `pip install whisperx`
- **Vorteile:**
  - Wort-genaue Zeitstempel
  - Sprecherdiarisierung integriert
  - VAD (Voice Activity Detection)

### 4. **Insanely Fast Whisper**
- **Geschwindigkeit:** Bis zu 10x schneller (mit GPU)
- **Qualit√§t:** Identisch zu OpenAI Whisper
- **Installation:** `pip install insanely-fast-whisper`
- **Vorteile:**
  - Optimiert f√ºr Batch-Processing
  - Nutzt Transformers library
  - Sehr schnell auf GPU

### 5. **SpeechRecognition mit Google/Azure**
- **Geschwindigkeit:** Echtzeit oder schneller
- **Qualit√§t:** Sehr gut, aber Internet erforderlich
- **Installation:** `pip install SpeechRecognition`
- **Nachteile:**
  - Ben√∂tigt Internet
  - Datenschutz-Bedenken
  - Kosten bei gro√üen Mengen

## üìä Geschwindigkeitsvergleich

| Tool | Geschwindigkeit | Qualit√§t | Offline | CPU/GPU |
|------|----------------|----------|---------|---------|
| OpenAI Whisper | 1x (Baseline) | 100% | ‚úÖ | Beide |
| faster-whisper | 4-5x | 100% | ‚úÖ | Beide |
| whisper.cpp | 3-4x | 98% | ‚úÖ | CPU |
| WhisperX | 2-3x | 100%+ | ‚úÖ | Beide |
| Insanely Fast | 10x | 100% | ‚úÖ | GPU |

## üõ†Ô∏è Integration in WhisperSprecherMatcher

Das System verwendet bereits **faster-whisper** als Standard! 

### Installation von faster-whisper:
```bash
pip install faster-whisper
```

### Verwendung erzwingen:
```bash
python3 auto_transcriber_v2.py --local
```

### Standard Whisper verwenden (falls Probleme):
```bash
python3 auto_transcriber_v2.py --standard-whisper --local
```

## üí° Empfehlungen

1. **F√ºr normale Nutzung:** faster-whisper (bereits integriert)
2. **F√ºr maximale Geschwindigkeit auf GPU:** Insanely Fast Whisper
3. **F√ºr Wort-genaue Timestamps:** WhisperX
4. **F√ºr alte/schwache Hardware:** whisper.cpp

## üîß Weitere Optimierungen

### Modell-Gr√∂√üe
- `tiny`: Sehr schnell, niedrigere Qualit√§t
- `base`: Schnell, gute Qualit√§t (Standard)
- `small`: Guter Kompromiss
- `medium`: Langsamer, bessere Qualit√§t
- `large`: Sehr langsam, beste Qualit√§t

### Batch-Processing
Mehrere Dateien gleichzeitig verarbeiten f√ºr bessere Effizienz.

### Hardware-Beschleunigung
- Apple Silicon: Metal Performance Shaders
- NVIDIA: CUDA
- AMD: ROCm 